{
  "endpoint_name": null,
  "id": "9977c617-d3c9-40f9-8cb7-2077f4f46788",
  "tags": null,
  "folder_id": "025fbe78-aa41-4b16-9f53-77009b8d268d",
  "gradient": null,
  "data": {
    "nodes": [
      {
        "id": "ChatInput-yq5pX",
        "type": "genericNode",
        "position": {
          "x": 13.187209446095608,
          "y": 648.4081710279081
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "files": {
                "trace_as_metadata": true,
                "file_path": "",
                "fileTypes": [
                  "txt",
                  "md",
                  "mdx",
                  "csv",
                  "json",
                  "yaml",
                  "yml",
                  "xml",
                  "html",
                  "htm",
                  "pdf",
                  "docx",
                  "py",
                  "sh",
                  "sql",
                  "js",
                  "ts",
                  "tsx",
                  "jpg",
                  "jpeg",
                  "png",
                  "bmp",
                  "image"
                ],
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "files",
                "value": "",
                "display_name": "Files",
                "advanced": true,
                "dynamic": false,
                "info": "Files to be sent with the message.",
                "title_case": false,
                "type": "file",
                "_input_type": "FileInput"
              },
              "background_color": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "background_color",
                "value": "",
                "display_name": "Background Color",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The background color of the icon.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "chat_icon": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "chat_icon",
                "value": "",
                "display_name": "Icon",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The icon of the message.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.base.data.utils import IMG_FILE_TYPES, TEXT_FILE_TYPES\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.inputs import BoolInput\nfrom langflow.io import DropdownInput, FileInput, MessageTextInput, MultilineInput, Output\nfrom langflow.schema.message import Message\nfrom langflow.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_NAME_USER, MESSAGE_SENDER_USER\n\n\nclass ChatInput(ChatComponent):\n    display_name = \"Chat Input\"\n    description = \"Get chat inputs from the Playground.\"\n    icon = \"MessagesSquare\"\n    name = \"ChatInput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            value=\"\",\n            info=\"Message to be passed as input.\",\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_USER,\n            info=\"Type of sender.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_USER,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        FileInput(\n            name=\"files\",\n            display_name=\"Files\",\n            file_types=TEXT_FILE_TYPES + IMG_FILE_TYPES,\n            info=\"Files to be sent with the message.\",\n            advanced=True,\n            is_list=True,\n        ),\n        MessageTextInput(\n            name=\"background_color\",\n            display_name=\"Background Color\",\n            info=\"The background color of the icon.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"chat_icon\",\n            display_name=\"Icon\",\n            info=\"The icon of the message.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"text_color\",\n            display_name=\"Text Color\",\n            info=\"The text color of the name\",\n            advanced=True,\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    def message_response(self) -> Message:\n        _background_color = self.background_color\n        _text_color = self.text_color\n        _icon = self.chat_icon\n        message = Message(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n            files=self.files,\n            properties={\"background_color\": _background_color, \"text_color\": _text_color, \"icon\": _icon},\n        )\n        if self.session_id and isinstance(message, Message) and self.should_store_message:\n            stored_message = self.send_message(\n                message,\n            )\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "tool_mode": false,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "Hello",
                "display_name": "Text",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Message to be passed as input.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "sender": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "Machine",
                  "User"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender",
                "value": "User",
                "display_name": "Sender Type",
                "advanced": true,
                "dynamic": false,
                "info": "Type of sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "sender_name": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender_name",
                "value": "User",
                "display_name": "Sender Name",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Name of the sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "session_id": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "session_id",
                "value": "",
                "display_name": "Session ID",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "should_store_message": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "should_store_message",
                "value": true,
                "display_name": "Store Messages",
                "advanced": true,
                "dynamic": false,
                "info": "Store the message in the history.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "text_color": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "text_color",
                "value": "",
                "display_name": "Text Color",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The text color of the name",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Get chat inputs from the Playground.",
            "icon": "MessagesSquare",
            "base_classes": [
              "Message"
            ],
            "display_name": "Chat Input",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "message",
                "display_name": "Message",
                "method": "message_response",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "files",
              "background_color",
              "chat_icon",
              "text_color"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.1"
          },
          "type": "ChatInput",
          "id": "ChatInput-yq5pX"
        },
        "selected": false,
        "width": 320,
        "height": 233,
        "positionAbsolute": {
          "x": 13.187209446095608,
          "y": 648.4081710279081
        },
        "dragging": false
      },
      {
        "id": "ChatOutput-vrPIs",
        "type": "genericNode",
        "position": {
          "x": 788.9256193164559,
          "y": 1058.8015369474988
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "background_color": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "background_color",
                "value": "",
                "display_name": "Background Color",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The background color of the icon.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "chat_icon": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "chat_icon",
                "value": "",
                "display_name": "Icon",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The icon of the message.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.base.io.chat import ChatComponent\nfrom langflow.inputs import BoolInput\nfrom langflow.io import DropdownInput, MessageInput, MessageTextInput, Output\nfrom langflow.schema.message import Message\nfrom langflow.schema.properties import Source\nfrom langflow.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_NAME_AI, MESSAGE_SENDER_USER\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"MessagesSquare\"\n    name = \"ChatOutput\"\n\n    inputs = [\n        MessageInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n        MessageTextInput(\n            name=\"background_color\",\n            display_name=\"Background Color\",\n            info=\"The background color of the icon.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"chat_icon\",\n            display_name=\"Icon\",\n            info=\"The icon of the message.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"text_color\",\n            display_name=\"Text Color\",\n            info=\"The text color of the name\",\n            advanced=True,\n        ),\n    ]\n    outputs = [\n        Output(\n            display_name=\"Message\",\n            name=\"message\",\n            method=\"message_response\",\n        ),\n    ]\n\n    def _build_source(self, _id: str | None, display_name: str | None, source: str | None) -> Source:\n        source_dict = {}\n        if _id:\n            source_dict[\"id\"] = _id\n        if display_name:\n            source_dict[\"display_name\"] = display_name\n        if source:\n            source_dict[\"source\"] = source\n        return Source(**source_dict)\n\n    def message_response(self) -> Message:\n        _source, _icon, _display_name, _source_id = self.get_properties_from_source_component()\n        _background_color = self.background_color\n        _text_color = self.text_color\n        if self.chat_icon:\n            _icon = self.chat_icon\n        message = self.input_value if isinstance(self.input_value, Message) else Message(text=self.input_value)\n        message.sender = self.sender\n        message.sender_name = self.sender_name\n        message.session_id = self.session_id\n        message.flow_id = self.graph.flow_id if hasattr(self, \"graph\") else None\n        message.properties.source = self._build_source(_source_id, _display_name, _source)\n        message.properties.icon = _icon\n        message.properties.background_color = _background_color\n        message.properties.text_color = _text_color\n        if self.session_id and isinstance(message, Message) and self.should_store_message:\n            stored_message = self.send_message(\n                message,\n            )\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "data_template": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "data_template",
                "value": "{text}",
                "display_name": "Data Template",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "input_value": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Text",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Message to be passed as output.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageInput"
              },
              "sender": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "Machine",
                  "User"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender",
                "value": "Machine",
                "display_name": "Sender Type",
                "advanced": true,
                "dynamic": false,
                "info": "Type of sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "sender_name": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender_name",
                "value": "AI",
                "display_name": "Sender Name",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Name of the sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "session_id": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "session_id",
                "value": "",
                "display_name": "Session ID",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "should_store_message": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "should_store_message",
                "value": true,
                "display_name": "Store Messages",
                "advanced": true,
                "dynamic": false,
                "info": "Store the message in the history.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "text_color": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "text_color",
                "value": "",
                "display_name": "Text Color",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The text color of the name",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Display a chat message in the Playground.",
            "icon": "MessagesSquare",
            "base_classes": [
              "Message"
            ],
            "display_name": "Chat Output",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "message",
                "display_name": "Message",
                "method": "message_response",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "data_template",
              "background_color",
              "chat_icon",
              "text_color"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.1"
          },
          "type": "ChatOutput",
          "id": "ChatOutput-vrPIs"
        },
        "selected": false,
        "width": 320,
        "height": 233,
        "positionAbsolute": {
          "x": 788.9256193164559,
          "y": 1058.8015369474988
        },
        "dragging": false
      },
      {
        "id": "Prompt-USl7n",
        "type": "genericNode",
        "position": {
          "x": 0.9444790387223065,
          "y": 936.0419649100365
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(self) -> Message:\n        prompt = Message.from_template(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    def post_code_processing(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "template": {
                "tool_mode": false,
                "trace_as_input": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "template",
                "value": "You are an advanced data analysis model with access to the average number of likes, shares, and comments for four types of posts: [\"reel\", \"carousel\", \"static_image\", \"story\"].\nHere is the data: {dataOfEachPost}\n\n\nWhen a user requests insights about a specific post type, your goal is to compare the engagement metrics (likes, shares, and comments) of that post type against all other post types.\n\nInstructions for analysis:\n\n**Always use calculator tool for doing mathematical operations / solving expressions.**\n\nIdentify the post type mentioned in the userâ€™s query (e.g., \"reel\", \"carousel\", \"static_image\", \"story\").\nFor the specified post type, compare its average engagement (likes, shares, and comments) against each of the other post types.\nProvide a comparison of how the specified post type performs relative to others. Include the percentage difference in engagement (likes, shares, and comments) between the specified post type and each of the other post types.\nOutput format example:\n\nIf the user asks, \"What are the engagement stats for reels?\"\nResponse:\n\"Reel posts have 40% higher engagement (likes, shares, and comments combined) than static posts, 30% more than carousel posts, and 5% less than story posts.\"\nExample Input/Output:\nUser Input: \"What are the stats of reel posts compared to other types?\"\n\nResponse:\n\"Reel posts have 40% higher engagement than static_image posts, 30% more than carousel posts, and 5% less than story posts. Reel posts perform particularly well in terms of likes, with an average of 500 likes, compared to 350 for static_image posts and 450 for carousel posts. Story posts, however, have higher shares than reel posts, with an average of 150 shares compared to 120 shares for reels.\"\nUser Input: \"How do carousel posts compare to others?\"\n\nResponse:\n\"Carousel posts have 20% more engagement than static_image posts, but 15% less than reel posts. Story posts perform similarly to carousel posts in terms of comments but have higher likes overall.\"\nUser Input: \"Tell me about static image posts.\"\n\nResponse:\n\"Static_image posts have 10% less engagement than carousel posts, 30% less than reels, and 25% less than story posts, particularly in terms of shares.\"",
                "display_name": "Template",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "prompt",
                "_input_type": "PromptInput"
              },
              "dataOfEachPost": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "name": "dataOfEachPost",
                "display_name": "dataOfEachPost",
                "advanced": false,
                "input_types": [
                  "Message",
                  "Text"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              }
            },
            "description": "Create a prompt template with dynamic variables.",
            "icon": "prompts",
            "is_input": null,
            "is_output": null,
            "is_composition": null,
            "base_classes": [
              "Message"
            ],
            "name": "",
            "display_name": "P1",
            "documentation": "",
            "custom_fields": {
              "template": [
                "dataOfEachPost"
              ]
            },
            "output_types": [],
            "full_path": null,
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "prompt",
                "hidden": null,
                "display_name": "Prompt Message",
                "method": "build_prompt",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null
              }
            ],
            "field_order": [
              "template"
            ],
            "beta": false,
            "legacy": false,
            "error": null,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.1"
          },
          "type": "Prompt",
          "id": "Prompt-USl7n"
        },
        "selected": false,
        "width": 320,
        "height": 346,
        "positionAbsolute": {
          "x": 0.9444790387223065,
          "y": 936.0419649100365
        },
        "dragging": false
      },
      {
        "id": "ParseData-7XyQC",
        "type": "genericNode",
        "position": {
          "x": -355.3585115762891,
          "y": 984.8920310554206
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "data": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "trace_as_input": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "data",
                "value": "",
                "display_name": "Data",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "The data to convert to text.",
                "title_case": false,
                "type": "other",
                "_input_type": "DataInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.custom import Component\nfrom langflow.helpers.data import data_to_text\nfrom langflow.io import DataInput, MultilineInput, Output, StrInput\nfrom langflow.schema.message import Message\n\n\nclass ParseDataComponent(Component):\n    display_name = \"Parse Data\"\n    description = \"Convert Data into plain text following a specified template.\"\n    icon = \"braces\"\n    name = \"ParseData\"\n\n    inputs = [\n        DataInput(name=\"data\", display_name=\"Data\", info=\"The data to convert to text.\"),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. \"\n            \"It can contain the keys {text}, {data} or any other key in the Data.\",\n            value=\"{text}\",\n        ),\n        StrInput(name=\"sep\", display_name=\"Separator\", advanced=True, value=\"\\n\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Text\", name=\"text\", method=\"parse_data\"),\n    ]\n\n    def parse_data(self) -> Message:\n        data = self.data if isinstance(self.data, list) else [self.data]\n        template = self.template\n\n        result_string = data_to_text(template, data, sep=self.sep)\n        self.status = result_string\n        return Message(text=result_string)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "display_name": "code"
              },
              "sep": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sep",
                "value": "\n",
                "display_name": "Separator",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "template": {
                "tool_mode": false,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "template",
                "value": "{text}",
                "display_name": "Template",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              }
            },
            "description": "Convert Data into plain text following a specified template.",
            "icon": "braces",
            "base_classes": [
              "Message"
            ],
            "display_name": "Parse Data",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text",
                "display_name": "Text",
                "method": "parse_data",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "data",
              "template",
              "sep"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "category": "processing",
            "key": "ParseData",
            "score": 0.007568328950209746,
            "lf_version": "1.1.1"
          },
          "type": "ParseData",
          "id": "ParseData-7XyQC"
        },
        "selected": false,
        "width": 320,
        "height": 302,
        "positionAbsolute": {
          "x": -355.3585115762891,
          "y": 984.8920310554206
        },
        "dragging": false
      },
      {
        "id": "CustomComponent-fbnej",
        "type": "genericNode",
        "position": {
          "x": -349.8922611121723,
          "y": 614.8381999045292
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "astradb_cname": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "astradb_cname",
                "value": "posts",
                "display_name": "Collection Name",
                "advanced": false,
                "dynamic": false,
                "info": "Enter the collection name",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from statistics import mean\r\nfrom langflow.schema import Data\r\nfrom astrapy import DataAPIClient\r\nfrom langchain_core.tools import StructuredTool\r\nfrom langchain_core.tools import ToolException\r\nfrom langflow.base.langchain_utilities.model import LCToolComponent\r\nfrom langflow.field_typing import Tool\r\n\r\n\r\n\r\nclass CustCompSchema(BaseModel):\r\n    \"\"\"Schema to define the input structure for the tool.\"\"\"\r\n\r\n    typeOfPost: str = Field(..., description=\"The type of post.. such as reel, carousel, etc.\")\r\n\r\n\r\nclass CustomComponent(LCToolComponent):\r\n    display_name = \"Average Calculator for a type of post.\"\r\n    description = \"Use it to calculate the average of a type of post.\"\r\n    icon = \"code\"\r\n    name = \"Average Calculator for a post type\"\r\n\r\n    inputs = [\r\n        StrInput(\r\n            name=\"astradb_cname\",\r\n            display_name=\"Collection Name\",\r\n            info=\"Enter the collection name\",\r\n            required=True,\r\n        ),\r\n        # MultilineInput(\r\n        #     name=\"typeOfPost\",\r\n        #     display_name=\"Type of post\",\r\n        #     info=\"Enter the type of post\",\r\n        #     required=True,\r\n        # ),\r\n        SecretStrInput(\r\n            name=\"tokenn\",\r\n            display_name=\"Astra DB Connection Token\",\r\n            info=\"Connection token for accessing Astra DB.\",\r\n            required=True,\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Text\", name=\"text\", method=\"build_output\"),\r\n        # Output(display_name=\"Tool\", name=\"avgTool\", method=\"build_tool\"),\r\n    ]\r\n\r\n    def build_output(self) -> Data:\r\n        astra_token = self.tokenn\r\n        collection_name = self.astradb_cname\r\n    \r\n        # List of post types\r\n        post_types = [\"reel\", \"carousel\", \"story\", \"static_image\"]\r\n    \r\n        client = DataAPIClient(astra_token)\r\n    \r\n        # Define the API endpoint URL (consider storing this securely in environment variables)\r\n        api_url = \"Please use your own API endpoint! Looks like this: (https://<id>.apps.astra.datastax.com)\"\r\n        \r\n        try:\r\n            # Try connecting to the database\r\n            db = client.get_database_by_api_endpoint(api_url)\r\n            posts_collection = db[collection_name]  # Ensure collection_name is used\r\n            \r\n            # Initialize the output dictionary to store results\r\n            avg_data = {}\r\n    \r\n            # Loop through each post type\r\n            for typeOfPost in post_types:\r\n                # Find posts with the specified post_type\r\n                customTypeOfPosts = posts_collection.find({\"post_type\": typeOfPost})\r\n                \r\n                # Initialize lists to collect likes, shares, and comments\r\n                likes = []\r\n                shares = []\r\n                comments = []\r\n                \r\n                # Loop through the posts to extract the 'likes', 'shares', and 'comments' fields\r\n                for post in customTypeOfPosts:\r\n                    if 'likes' in post:\r\n                        likes.append(post['likes'])\r\n                    if 'shares' in post:\r\n                        shares.append(post['shares'])\r\n                    if 'comments' in post:\r\n                        comments.append(post['comments'])\r\n    \r\n                # Calculate average likes if there are any likes\r\n                if likes:\r\n                    avg_likes = round(mean(likes), 2)\r\n                    avg_data[typeOfPost] = avg_data.get(typeOfPost, {})\r\n                    avg_data[typeOfPost]['likes'] = avg_likes\r\n                else:\r\n                    avg_data[typeOfPost] = avg_data.get(typeOfPost, {})\r\n                    avg_data[typeOfPost]['likes'] = \"No data\"\r\n    \r\n                # Calculate average shares if there are any shares\r\n                if shares:\r\n                    avg_shares = round(mean(shares), 2)\r\n                    avg_data[typeOfPost]['shares'] = avg_shares\r\n                else:\r\n                    avg_data[typeOfPost]['shares'] = \"No data\"\r\n    \r\n                # Calculate average comments if there are any comments\r\n                if comments:\r\n                    avg_comments = round(mean(comments), 2)\r\n                    avg_data[typeOfPost]['comments'] = avg_comments\r\n                else:\r\n                    avg_data[typeOfPost]['comments'] = \"No data\"\r\n    \r\n            # Format the result to include averages for each post type\r\n            result = \"\"\r\n            for post_type, data in avg_data.items():\r\n                result += f\"Post Type: {post_type}\\n\"\r\n                result += f\"  Avg Likes: {data['likes']}\\n\"\r\n                result += f\"  Avg Shares: {data['shares']}\\n\"\r\n                result += f\"  Avg Comments: {data['comments']}\\n\\n\"\r\n    \r\n            self.status = \"Successfully calculated averages for all post types\"\r\n        \r\n        except KeyError as e:\r\n            # Handle missing keys in the response\r\n            result = f\"KeyError: Missing expected field {str(e)} in post data.\"\r\n            self.status = \"Error: Missing key\"\r\n        except ConnectionError as e:\r\n            # Handle network connection issues\r\n            result = f\"ConnectionError: Failed to connect to the database. {str(e)}\"\r\n            self.status = \"Error: Connection issue\"\r\n        except Exception as e:\r\n            # General exception for any other errors\r\n            result = f\"An error occurred: {str(e)}\"\r\n            self.status = \"Error executing query\"\r\n    \r\n        # Return the result wrapped in the Data class\r\n        data = Data(text=result)\r\n        return data\r\n\r\n    \r\n    \r\n    def build_tool(self) -> Tool:\r\n        \"\"\"Builds the Average Calculator tool.\r\n\r\n        Returns:\r\n            StructuredTool: The built average calculator tool.\r\n        \"\"\"\r\n\r\n        try:\r\n            return StructuredTool.from_function(\r\n                name=self.name,\r\n                description=self.description,\r\n                func=self.build_output,\r\n                args_schema=CustCompSchema,\r\n            )\r\n\r\n        except Exception as exc:\r\n            msg = f\"Failed to build the YouTube transcripts tool: {exc!s}\"\r\n            raise RuntimeError(msg) from exc\r\n\r\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "tokenn": {
                "load_from_db": true,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "tokenn",
                "value": "",
                "display_name": "Astra DB Connection Token",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Connection token for accessing Astra DB.",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              }
            },
            "description": "Use it to calculate the average of a type of post.",
            "icon": "code",
            "base_classes": [
              "Data"
            ],
            "display_name": "AvgCalc_EachTypeOfPost",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "text",
                "display_name": "Text",
                "method": "build_output",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "astradb_cname",
              "tokenn"
            ],
            "beta": false,
            "legacy": false,
            "edited": true,
            "metadata": {},
            "tool_mode": false
          },
          "type": "CustomComponent",
          "id": "CustomComponent-fbnej"
        },
        "selected": false,
        "width": 320,
        "height": 340,
        "positionAbsolute": {
          "x": -349.8922611121723,
          "y": 614.8381999045292
        },
        "dragging": false
      },
      {
        "id": "Prompt-qMUM1",
        "type": "genericNode",
        "position": {
          "x": -360.4911290460371,
          "y": 1353.7833313475114
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(self) -> Message:\n        prompt = Message.from_template(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    def post_code_processing(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "template": {
                "tool_mode": false,
                "trace_as_input": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "template",
                "value": "You are an advanced data analysis model with access to the average number of likes, shares, and comments for four types of posts: [\"reel\", \"carousel\", \"static_image\", \"story\"].\nHere is the data: {dataOfEachPost}\n\n\nWhen a user requests insights about a specific post type, your goal is to compare the engagement metrics (likes, shares, and comments) of that post type against all other post types.\n\nInstructions for analysis:\n\n**Always use calculator tool for doing mathematical operations / solving expressions.**\n\nIdentify the post type mentioned in the userâ€™s query (e.g., \"reel\", \"carousel\", \"static_image\", \"story\").\nFor the specified post type, compare its average engagement (likes, shares, and comments) against each of the other post types.\nProvide a comparison of how the specified post type performs relative to others. Include the percentage difference in engagement (likes, shares, and comments) between the specified post type and each of the other post types.\n\nOutput format example:\n**This is just an example dont use it in giving output**\nIf the user asks, \"What are the engagement stats for reels?\"\nResponse:\n\"Reel posts have 40% higher engagement (likes, shares, and comments combined) than static posts, 30% more than carousel posts, and 5% less than story posts.\"",
                "display_name": "Template",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "prompt",
                "_input_type": "PromptInput"
              },
              "dataOfEachPost": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "name": "dataOfEachPost",
                "display_name": "dataOfEachPost",
                "advanced": false,
                "input_types": [
                  "Message",
                  "Text"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              }
            },
            "description": "Create a prompt template with dynamic variables.",
            "icon": "prompts",
            "is_input": null,
            "is_output": null,
            "is_composition": null,
            "base_classes": [
              "Message"
            ],
            "name": "",
            "display_name": "P2",
            "documentation": "",
            "custom_fields": {
              "template": [
                "dataOfEachPost"
              ]
            },
            "output_types": [],
            "full_path": null,
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "prompt",
                "hidden": null,
                "display_name": "Prompt Message",
                "method": "build_prompt",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null
              }
            ],
            "field_order": [
              "template"
            ],
            "beta": false,
            "legacy": false,
            "error": null,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.1"
          },
          "type": "Prompt",
          "id": "Prompt-qMUM1"
        },
        "selected": false,
        "width": 320,
        "height": 346,
        "positionAbsolute": {
          "x": -360.4911290460371,
          "y": 1353.7833313475114
        },
        "dragging": false
      },
      {
        "id": "GoogleGenerativeAIModel-lYbFS",
        "type": "genericNode",
        "position": {
          "x": 420.2720384659259,
          "y": 796.2989266722814
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "output_parser": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "output_parser",
                "value": "",
                "display_name": "Output Parser",
                "advanced": true,
                "input_types": [
                  "OutputParser"
                ],
                "dynamic": false,
                "info": "The parser to use to parse the output of the model",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from pydantic.v1 import SecretStr\n\nfrom langflow.base.models.google_generative_ai_constants import GOOGLE_GENERATIVE_AI_MODELS\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.field_typing import LanguageModel\nfrom langflow.inputs import DropdownInput, FloatInput, IntInput, SecretStrInput\nfrom langflow.inputs.inputs import HandleInput\n\n\nclass GoogleGenerativeAIComponent(LCModelComponent):\n    display_name = \"Google Generative AI\"\n    description = \"Generate text using Google Generative AI.\"\n    icon = \"GoogleGenerativeAI\"\n    name = \"GoogleGenerativeAIModel\"\n\n    inputs = [\n        *LCModelComponent._base_inputs,\n        IntInput(\n            name=\"max_output_tokens\", display_name=\"Max Output Tokens\", info=\"The maximum number of tokens to generate.\"\n        ),\n        DropdownInput(\n            name=\"model\",\n            display_name=\"Model\",\n            info=\"The name of the model to use.\",\n            options=GOOGLE_GENERATIVE_AI_MODELS,\n            value=\"gemini-1.5-pro\",\n        ),\n        SecretStrInput(\n            name=\"google_api_key\",\n            display_name=\"Google API Key\",\n            info=\"The Google API Key to use for the Google Generative AI.\",\n        ),\n        FloatInput(\n            name=\"top_p\",\n            display_name=\"Top P\",\n            info=\"The maximum cumulative probability of tokens to consider when sampling.\",\n            advanced=True,\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\n        IntInput(\n            name=\"n\",\n            display_name=\"N\",\n            info=\"Number of chat completions to generate for each prompt. \"\n            \"Note that the API may not return the full n completions if duplicates are generated.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"top_k\",\n            display_name=\"Top K\",\n            info=\"Decode using top-k sampling: consider the set of top_k most probable tokens. Must be positive.\",\n            advanced=True,\n        ),\n        HandleInput(\n            name=\"output_parser\",\n            display_name=\"Output Parser\",\n            info=\"The parser to use to parse the output of the model\",\n            advanced=True,\n            input_types=[\"OutputParser\"],\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        try:\n            from langchain_google_genai import ChatGoogleGenerativeAI\n        except ImportError as e:\n            msg = \"The 'langchain_google_genai' package is required to use the Google Generative AI model.\"\n            raise ImportError(msg) from e\n\n        google_api_key = self.google_api_key\n        model = self.model\n        max_output_tokens = self.max_output_tokens\n        temperature = self.temperature\n        top_k = self.top_k\n        top_p = self.top_p\n        n = self.n\n\n        return ChatGoogleGenerativeAI(\n            model=model,\n            max_output_tokens=max_output_tokens or None,\n            temperature=temperature,\n            top_k=top_k or None,\n            top_p=top_p or None,\n            n=n or 1,\n            google_api_key=SecretStr(google_api_key).get_secret_value(),\n        )\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "google_api_key": {
                "load_from_db": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "google_api_key",
                "value": "",
                "display_name": "Google API Key",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The Google API Key to use for the Google Generative AI.",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              },
              "input_value": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Input",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageInput"
              },
              "max_output_tokens": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "max_output_tokens",
                "value": "",
                "display_name": "Max Output Tokens",
                "advanced": false,
                "dynamic": false,
                "info": "The maximum number of tokens to generate.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "model": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "gemini-1.5-pro",
                  "gemini-1.5-flash",
                  "gemini-1.5-flash-8b",
                  "gemini-1.0-pro",
                  "gemini-1.0-pro-vision",
                  "gemini-1.5-pro-001",
                  "gemini-1.5-pro-002",
                  "gemini-1.5-flash-001",
                  "gemini-1.5-flash-002",
                  "gemini-1.5-pro-exp-0827",
                  "gemini-1.5-flash-exp-0827",
                  "gemini-1.5-flash-8b-exp-0827",
                  "gemini-1.5-flash-8b-exp-0924",
                  "gemini-exp-1114"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model",
                "value": "gemini-1.5-pro",
                "display_name": "Model",
                "advanced": false,
                "dynamic": false,
                "info": "The name of the model to use.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "n": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "n",
                "value": "",
                "display_name": "N",
                "advanced": true,
                "dynamic": false,
                "info": "Number of chat completions to generate for each prompt. Note that the API may not return the full n completions if duplicates are generated.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "stream": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "stream",
                "value": false,
                "display_name": "Stream",
                "advanced": false,
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "system_message": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "system_message",
                "value": "",
                "display_name": "System Message",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "System message to pass to the model.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "temperature": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "temperature",
                "value": 0.1,
                "display_name": "Temperature",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "float",
                "_input_type": "FloatInput"
              },
              "top_k": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "top_k",
                "value": "",
                "display_name": "Top K",
                "advanced": true,
                "dynamic": false,
                "info": "Decode using top-k sampling: consider the set of top_k most probable tokens. Must be positive.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "top_p": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "top_p",
                "value": "",
                "display_name": "Top P",
                "advanced": true,
                "dynamic": false,
                "info": "The maximum cumulative probability of tokens to consider when sampling.",
                "title_case": false,
                "type": "float",
                "_input_type": "FloatInput"
              }
            },
            "description": "Generate text using Google Generative AI.",
            "icon": "GoogleGenerativeAI",
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "display_name": "Google Generative AI",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text_output",
                "display_name": "Text",
                "method": "text_response",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": []
              },
              {
                "types": [
                  "LanguageModel"
                ],
                "selected": "LanguageModel",
                "name": "model_output",
                "display_name": "Language Model",
                "method": "build_model",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": []
              }
            ],
            "field_order": [
              "input_value",
              "system_message",
              "stream",
              "max_output_tokens",
              "model",
              "google_api_key",
              "top_p",
              "temperature",
              "n",
              "top_k",
              "output_parser"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.1"
          },
          "type": "GoogleGenerativeAIModel",
          "id": "GoogleGenerativeAIModel-lYbFS"
        },
        "selected": false,
        "width": 320,
        "height": 758,
        "positionAbsolute": {
          "x": 420.2720384659259,
          "y": 796.2989266722814
        },
        "dragging": false
      },
      {
        "id": "Prompt-p3Cx8",
        "type": "genericNode",
        "position": {
          "x": 15.531206219350679,
          "y": 1343.2287174147455
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(self) -> Message:\n        prompt = Message.from_template(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    def post_code_processing(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "template": {
                "tool_mode": false,
                "trace_as_input": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "template",
                "value": "You are an advanced data analysis model with access to the average number of likes, shares, and comments for four types of posts: [\"reel\", \"carousel\", \"static_image\", \"story\"].\nHere is the data: {dataOfEachPost}\n\n\nWhen a user requests insights about a specific post type, your goal is to compare the engagement metrics (likes, shares, and comments) of that post type against all other post types.\n\nInstructions for analysis:\n\n**Always use calculator tool for doing mathematical operations / solving expressions.**\n\nIdentify the post type mentioned in the userâ€™s query (e.g., \"reel\", \"carousel\", \"static_image\", \"story\").\nFor the specified post type, compare its average engagement (likes, shares, and comments) against each of the other post types.\nProvide a comparison of how the specified post type performs relative to others. Include the percentage difference in engagement (likes, shares, and comments) between the specified post type and each of the other post types.\n\nOutput format example:\n**This is just an example dont use it in giving output**\n\nIf the user asks, \"What are the engagement stats for static images?\"\nResponse: (given below)\n\"\"\"\nStatic image posts have the following average engagement metrics:\n- Likes: 125\n- Shares: 7.5\n- Comments: 3.5\n\nHere's a breakdown of static image post performance compared to other post types:\n\n*   **vs. Reel:**\n    *   Static image posts receive 85% fewer likes than reel posts.\n    *   Static image posts receive 97% fewer shares than reel posts.\n    *   Static image posts receive 98% fewer comments than reel posts.\n\n*   **vs. Carousel:**\n    *   Static image posts receive 54% fewer likes than carousel posts.\n    *   Static image posts receive 81% fewer shares than carousel posts.\n    *   Static image posts receive 82% fewer comments than carousel posts.\n\n*   **vs. Story:**\n    *   Static image posts receive 75% fewer likes than story posts.\n    *   Static image posts receive 85% fewer shares than story posts.\n    *   Static image posts receive 86% fewer comments than story posts.\n\nSummary:\n\nStatic image posts generally have the lowest engagement compared to all other post types.  They receive significantly fewer likes, shares, and comments.\n\"\"\"\n",
                "display_name": "Template",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "prompt",
                "_input_type": "PromptInput"
              },
              "dataOfEachPost": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "name": "dataOfEachPost",
                "display_name": "dataOfEachPost",
                "advanced": false,
                "input_types": [
                  "Message",
                  "Text"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              }
            },
            "description": "Create a prompt template with dynamic variables.",
            "icon": "prompts",
            "is_input": null,
            "is_output": null,
            "is_composition": null,
            "base_classes": [
              "Message"
            ],
            "name": "",
            "display_name": "P3",
            "documentation": "",
            "custom_fields": {
              "template": [
                "dataOfEachPost"
              ]
            },
            "output_types": [],
            "full_path": null,
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "prompt",
                "hidden": null,
                "display_name": "Prompt Message",
                "method": "build_prompt",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null
              }
            ],
            "field_order": [
              "template"
            ],
            "beta": false,
            "legacy": false,
            "error": null,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.1"
          },
          "type": "Prompt",
          "id": "Prompt-p3Cx8"
        },
        "selected": false,
        "width": 320,
        "height": 346,
        "positionAbsolute": {
          "x": 15.531206219350679,
          "y": 1343.2287174147455
        },
        "dragging": false
      },
      {
        "id": "note-roxGK",
        "type": "noteNode",
        "position": {
          "x": -735.2205112804343,
          "y": 602.59870836906
        },
        "data": {
          "node": {
            "description": "Our custom component, 'AvgCalc,' was developed to handle database connections and perform calculations. We implemented this solution because the AI was not processing the data accurately, leading to inconsistent analysis results for the same query. To ensure precise and reliable outcomes, we now manually handle the calculation process before passing the results to the AI for analysis.\n\n**NOTE** \nPlease edit the Avg_Calc_EachTypeOfPost Component code and then enter your own database API key to make it work!",
            "display_name": "",
            "documentation": "",
            "template": {}
          },
          "type": "note",
          "id": "note-roxGK"
        },
        "width": 325,
        "height": 374,
        "selected": true,
        "dragging": false,
        "positionAbsolute": {
          "x": -735.2205112804343,
          "y": 602.59870836906
        },
        "style": {
          "width": 325,
          "height": 374
        },
        "resizing": false
      }
    ],
    "edges": [
      {
        "source": "ParseData-7XyQC",
        "sourceHandle": "{Å“dataTypeÅ“:Å“ParseDataÅ“,Å“idÅ“:Å“ParseData-7XyQCÅ“,Å“nameÅ“:Å“textÅ“,Å“output_typesÅ“:[Å“MessageÅ“]}",
        "target": "Prompt-USl7n",
        "targetHandle": "{Å“fieldNameÅ“:Å“dataOfEachPostÅ“,Å“idÅ“:Å“Prompt-USl7nÅ“,Å“inputTypesÅ“:[Å“MessageÅ“,Å“TextÅ“],Å“typeÅ“:Å“strÅ“}",
        "data": {
          "targetHandle": {
            "fieldName": "dataOfEachPost",
            "id": "Prompt-USl7n",
            "inputTypes": [
              "Message",
              "Text"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ParseData",
            "id": "ParseData-7XyQC",
            "name": "text",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-ParseData-7XyQC{Å“dataTypeÅ“:Å“ParseDataÅ“,Å“idÅ“:Å“ParseData-7XyQCÅ“,Å“nameÅ“:Å“textÅ“,Å“output_typesÅ“:[Å“MessageÅ“]}-Prompt-USl7n{Å“fieldNameÅ“:Å“dataOfEachPostÅ“,Å“idÅ“:Å“Prompt-USl7nÅ“,Å“inputTypesÅ“:[Å“MessageÅ“,Å“TextÅ“],Å“typeÅ“:Å“strÅ“}",
        "animated": false,
        "className": "",
        "selected": false
      },
      {
        "source": "ParseData-7XyQC",
        "sourceHandle": "{Å“dataTypeÅ“:Å“ParseDataÅ“,Å“idÅ“:Å“ParseData-7XyQCÅ“,Å“nameÅ“:Å“textÅ“,Å“output_typesÅ“:[Å“MessageÅ“]}",
        "target": "Prompt-qMUM1",
        "targetHandle": "{Å“fieldNameÅ“:Å“dataOfEachPostÅ“,Å“idÅ“:Å“Prompt-qMUM1Å“,Å“inputTypesÅ“:[Å“MessageÅ“,Å“TextÅ“],Å“typeÅ“:Å“strÅ“}",
        "data": {
          "targetHandle": {
            "fieldName": "dataOfEachPost",
            "id": "Prompt-qMUM1",
            "inputTypes": [
              "Message",
              "Text"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ParseData",
            "id": "ParseData-7XyQC",
            "name": "text",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-ParseData-7XyQC{Å“dataTypeÅ“:Å“ParseDataÅ“,Å“idÅ“:Å“ParseData-7XyQCÅ“,Å“nameÅ“:Å“textÅ“,Å“output_typesÅ“:[Å“MessageÅ“]}-Prompt-qMUM1{Å“fieldNameÅ“:Å“dataOfEachPostÅ“,Å“idÅ“:Å“Prompt-qMUM1Å“,Å“inputTypesÅ“:[Å“MessageÅ“,Å“TextÅ“],Å“typeÅ“:Å“strÅ“}",
        "animated": false,
        "className": "",
        "selected": false
      },
      {
        "source": "ParseData-7XyQC",
        "sourceHandle": "{Å“dataTypeÅ“:Å“ParseDataÅ“,Å“idÅ“:Å“ParseData-7XyQCÅ“,Å“nameÅ“:Å“textÅ“,Å“output_typesÅ“:[Å“MessageÅ“]}",
        "target": "Prompt-p3Cx8",
        "targetHandle": "{Å“fieldNameÅ“:Å“dataOfEachPostÅ“,Å“idÅ“:Å“Prompt-p3Cx8Å“,Å“inputTypesÅ“:[Å“MessageÅ“,Å“TextÅ“],Å“typeÅ“:Å“strÅ“}",
        "data": {
          "targetHandle": {
            "fieldName": "dataOfEachPost",
            "id": "Prompt-p3Cx8",
            "inputTypes": [
              "Message",
              "Text"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ParseData",
            "id": "ParseData-7XyQC",
            "name": "text",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-ParseData-7XyQC{Å“dataTypeÅ“:Å“ParseDataÅ“,Å“idÅ“:Å“ParseData-7XyQCÅ“,Å“nameÅ“:Å“textÅ“,Å“output_typesÅ“:[Å“MessageÅ“]}-Prompt-p3Cx8{Å“fieldNameÅ“:Å“dataOfEachPostÅ“,Å“idÅ“:Å“Prompt-p3Cx8Å“,Å“inputTypesÅ“:[Å“MessageÅ“,Å“TextÅ“],Å“typeÅ“:Å“strÅ“}",
        "animated": false,
        "className": "",
        "selected": false
      },
      {
        "source": "Prompt-p3Cx8",
        "sourceHandle": "{Å“dataTypeÅ“:Å“PromptÅ“,Å“idÅ“:Å“Prompt-p3Cx8Å“,Å“nameÅ“:Å“promptÅ“,Å“output_typesÅ“:[Å“MessageÅ“]}",
        "target": "GoogleGenerativeAIModel-lYbFS",
        "targetHandle": "{Å“fieldNameÅ“:Å“system_messageÅ“,Å“idÅ“:Å“GoogleGenerativeAIModel-lYbFSÅ“,Å“inputTypesÅ“:[Å“MessageÅ“],Å“typeÅ“:Å“strÅ“}",
        "data": {
          "targetHandle": {
            "fieldName": "system_message",
            "id": "GoogleGenerativeAIModel-lYbFS",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "Prompt",
            "id": "Prompt-p3Cx8",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-Prompt-p3Cx8{Å“dataTypeÅ“:Å“PromptÅ“,Å“idÅ“:Å“Prompt-p3Cx8Å“,Å“nameÅ“:Å“promptÅ“,Å“output_typesÅ“:[Å“MessageÅ“]}-GoogleGenerativeAIModel-lYbFS{Å“fieldNameÅ“:Å“system_messageÅ“,Å“idÅ“:Å“GoogleGenerativeAIModel-lYbFSÅ“,Å“inputTypesÅ“:[Å“MessageÅ“],Å“typeÅ“:Å“strÅ“}",
        "animated": false,
        "className": "",
        "selected": false
      },
      {
        "source": "GoogleGenerativeAIModel-lYbFS",
        "sourceHandle": "{Å“dataTypeÅ“:Å“GoogleGenerativeAIModelÅ“,Å“idÅ“:Å“GoogleGenerativeAIModel-lYbFSÅ“,Å“nameÅ“:Å“text_outputÅ“,Å“output_typesÅ“:[Å“MessageÅ“]}",
        "target": "ChatOutput-vrPIs",
        "targetHandle": "{Å“fieldNameÅ“:Å“input_valueÅ“,Å“idÅ“:Å“ChatOutput-vrPIsÅ“,Å“inputTypesÅ“:[Å“MessageÅ“],Å“typeÅ“:Å“strÅ“}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ChatOutput-vrPIs",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "GoogleGenerativeAIModel",
            "id": "GoogleGenerativeAIModel-lYbFS",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-GoogleGenerativeAIModel-lYbFS{Å“dataTypeÅ“:Å“GoogleGenerativeAIModelÅ“,Å“idÅ“:Å“GoogleGenerativeAIModel-lYbFSÅ“,Å“nameÅ“:Å“text_outputÅ“,Å“output_typesÅ“:[Å“MessageÅ“]}-ChatOutput-vrPIs{Å“fieldNameÅ“:Å“input_valueÅ“,Å“idÅ“:Å“ChatOutput-vrPIsÅ“,Å“inputTypesÅ“:[Å“MessageÅ“],Å“typeÅ“:Å“strÅ“}",
        "animated": false,
        "className": "",
        "selected": false
      },
      {
        "source": "ChatInput-yq5pX",
        "sourceHandle": "{Å“dataTypeÅ“:Å“ChatInputÅ“,Å“idÅ“:Å“ChatInput-yq5pXÅ“,Å“nameÅ“:Å“messageÅ“,Å“output_typesÅ“:[Å“MessageÅ“]}",
        "target": "GoogleGenerativeAIModel-lYbFS",
        "targetHandle": "{Å“fieldNameÅ“:Å“input_valueÅ“,Å“idÅ“:Å“GoogleGenerativeAIModel-lYbFSÅ“,Å“inputTypesÅ“:[Å“MessageÅ“],Å“typeÅ“:Å“strÅ“}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "GoogleGenerativeAIModel-lYbFS",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ChatInput",
            "id": "ChatInput-yq5pX",
            "name": "message",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-ChatInput-yq5pX{Å“dataTypeÅ“:Å“ChatInputÅ“,Å“idÅ“:Å“ChatInput-yq5pXÅ“,Å“nameÅ“:Å“messageÅ“,Å“output_typesÅ“:[Å“MessageÅ“]}-GoogleGenerativeAIModel-lYbFS{Å“fieldNameÅ“:Å“input_valueÅ“,Å“idÅ“:Å“GoogleGenerativeAIModel-lYbFSÅ“,Å“inputTypesÅ“:[Å“MessageÅ“],Å“typeÅ“:Å“strÅ“}",
        "animated": false,
        "className": "",
        "selected": false
      },
      {
        "source": "CustomComponent-fbnej",
        "sourceHandle": "{Å“dataTypeÅ“:Å“CustomComponentÅ“,Å“idÅ“:Å“CustomComponent-fbnejÅ“,Å“nameÅ“:Å“textÅ“,Å“output_typesÅ“:[Å“DataÅ“]}",
        "target": "ParseData-7XyQC",
        "targetHandle": "{Å“fieldNameÅ“:Å“dataÅ“,Å“idÅ“:Å“ParseData-7XyQCÅ“,Å“inputTypesÅ“:[Å“DataÅ“],Å“typeÅ“:Å“otherÅ“}",
        "data": {
          "targetHandle": {
            "fieldName": "data",
            "id": "ParseData-7XyQC",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "CustomComponent",
            "id": "CustomComponent-fbnej",
            "name": "text",
            "output_types": [
              "Data"
            ]
          }
        },
        "id": "reactflow__edge-CustomComponent-fbnej{Å“dataTypeÅ“:Å“CustomComponentÅ“,Å“idÅ“:Å“CustomComponent-fbnejÅ“,Å“nameÅ“:Å“textÅ“,Å“output_typesÅ“:[Å“DataÅ“]}-ParseData-7XyQC{Å“fieldNameÅ“:Å“dataÅ“,Å“idÅ“:Å“ParseData-7XyQCÅ“,Å“inputTypesÅ“:[Å“DataÅ“],Å“typeÅ“:Å“otherÅ“}",
        "className": ""
      }
    ],
    "viewport": {
      "x": 392.9833705708229,
      "y": -193.29689493912463,
      "zoom": 0.3821224592864025
    }
  },
  "is_component": false,
  "updated_at": "2025-01-10T01:21:37+00:00",
  "icon": null,
  "name": "GithubUpload",
  "icon_bg_color": null,
  "webhook": false,
  "user_id": "81fd83c1-b119-4fd3-810a-deb494aff58a",
  "description": "Analyzes a type of post by comparing its data with other type of posts."
}